<div>OLAP workloads tend to answer specific business intelligence questions, such as the number of sales of product X over duration Y, which requires values from at most several columns to fulfill this request. Precise access to these needed columns can be granted instantly in column-store systems due to how all record attributes are stored, which increases query performance for these OLAP workloads since less data has to be read and processed. In contrast, row-store systems must retrieve all record attributes and dispose of irrelevant ones (Figure <span class="au-ref raw v1">\ref{321131}</span>). This rationale has led to the question whether storing clinical data in columnar DBMSs could increase analytical workload performance.</div><div></div><h3><b>Approach</b></h3><div><b>For this benchmark, the openly accessible MIMIC-III v1.4 (Medical Information Mart for Intensive Care III) dataset is used. This big dataset (~33 GB) contains eleven years of observational health data resulting from approximately 60,000 intensive care unit admissions from over 40,000 patients and consists of bedside vital sign measurements (approximately 1 per hour), laboratory tests, medications, demographics, and multiple other variables.</b></div><div><b>The data is then conformed to a common data model: the i2b2 data mart model, which is based on the star schema structure. Here, a single central fact table is surrounded by dimension tables. The fact table solely stores “facts”, which is a single observation on a specific patient in the field of healthcare. For example, the observation “110 bpm heart rate” or “diagnosis of diabetes.” For each fact several attributes are stored, such as the IDs of the patient, provider and hospital admission, as well as the concept code for the specific observation and start and end dates.</b></div><div><b>Additional information related to the attributes of the fact table is stored in the dimension tables. For instance, the patient dimension table stores a patient’s date of birth, sex, age, marital status, and other parameters.</b></div><div><b>The four different open-source database management systems (DBMS) that are being profiled in this benchmark are: Apache Druid, ClickHouse, MonetDB, and PostgreSQL. These systems differ, amongst other things, in storage architecture and are explained more in-depth in the next section.</b></div><div><b>The benchmark consists of over 40 highly variable queries, each with different complexity and applicability. Each query will be repeated q times, while the benchmark itself is run b times. Random parametrization for each b round ensures fairer performance testing. Several components will be profiled at query level during each benchmark:</b></div><ul><li><div><b>Query execution time;</b></div></li><li><div><b>Current CPU usage (average of all cores);</b></div></li><li><div><b>CPU load average (1, 5, and 15 minutes);</b></div></li><li><div><b>Free/available memory;</b></div></li><li><div><b>Buffered memory;</b></div></li><li><div><b>Cached memory;</b></div></li></ul><div><b>In addition, DBMS optimization will be analyzed by comparing benchmarks with default settings versus hardware and software optimized configurations. Downscaling (removing data) and upscaling (copy data) the MIMIC-III dataset allows for scalability analysis. Lastly, database stability testing is performed.</b></div>